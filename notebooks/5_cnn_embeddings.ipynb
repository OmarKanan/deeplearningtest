{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, \\\n",
    "    classification_report\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, \\\n",
    "    StratifiedShuffleSplit, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../Data/Learn/labels.pkl\", \"rb\") as f:\n",
    "    learn_labels = pickle.load(f)\n",
    "\n",
    "with open(\"../Data/generated/my_learn_sequences.pkl\", \"rb\") as f:\n",
    "    learn_sequences = pickle.load(f)\n",
    "\n",
    "with open(\"../Data/generated/my_embeddings.pkl\", \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "# Remove unknown words row\n",
    "embeddings = embeddings[:-1, :]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    learn_sequences, learn_labels, test_size=0.3,\n",
    "    shuffle=True, stratify=learn_labels, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28935, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DNNModel(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,\n",
    "                 sentence_length,\n",
    "                 embeddings,\n",
    "                 filters_by_ksize=5,\n",
    "                 kernel_sizes=(2,),\n",
    "                 batch_size=128,\n",
    "                 learning_rate=0.1,\n",
    "                 dropout_keep_prob=1.0,\n",
    "                 model_name=None,\n",
    "                 checkpoints_dir=\"../checkpoints/\",\n",
    "                 ):\n",
    "        self.sentence_length = sentence_length\n",
    "        self.embeddings = embeddings\n",
    "        self.embedding_dim = self.embeddings.shape[1]\n",
    "        self.filters_by_ksize = filters_by_ksize\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_keep_prob = dropout_keep_prob\n",
    "        self.features_key = \"x\"\n",
    "        self.weight_key = \"weight\"\n",
    "        self.set_model_directory(checkpoints_dir, model_name)\n",
    "\n",
    "    def set_model_directory(self, checkpoints_dir, model_name):\n",
    "        if model_name is not None:\n",
    "            self.model_dir = checkpoints_dir + model_name\n",
    "            # Check model_dir doesn't already exist\n",
    "            if os.path.exists(self.model_dir):\n",
    "                raise ValueError(\"model_dir already exists\")\n",
    "        else:\n",
    "            self.model_dir = None\n",
    "\n",
    "    def check_warm_start(self, warm_start):\n",
    "        if warm_start:\n",
    "            # Check if model was already fitted\n",
    "            try:\n",
    "                self.classifier_\n",
    "            except:\n",
    "                warm_start = False\n",
    "        return warm_start\n",
    "    \n",
    "    def create_dnn_classifier(self):\n",
    "        # Columns of X\n",
    "        self.feature_columns_ = [tf.feature_column.numeric_column(\n",
    "            key=self.features_key, shape=self.sentence_length\n",
    "        )]\n",
    "        # Model parameters\n",
    "        params = {\n",
    "            \"feature_columns\": self.feature_columns_,\n",
    "            \"n_classes\": self.n_classes_,\n",
    "        }\n",
    "        # Config\n",
    "        run_config = tf.estimator.RunConfig(\n",
    "            model_dir=self.model_dir,\n",
    "            log_step_count_steps=10,\n",
    "        )\n",
    "        # Create model\n",
    "        model = tf.estimator.Estimator(model_fn=self.model_fn,\n",
    "                                       model_dir=self.model_dir,\n",
    "                                       params=params,\n",
    "                                       config=run_config)\n",
    "        model = tf.contrib.estimator.add_metrics(model, self.f1_score)\n",
    "        return model\n",
    "        \n",
    "    def f1_score(self, labels, predictions):\n",
    "        return {\"f1-score\": self.f1_metric_fn(labels=labels, predictions=predictions)}\n",
    "    \n",
    "    def f1_metric_fn(self, labels, predictions):\n",
    "        p, p_op = tf.metrics.precision(labels=labels, predictions=predictions)\n",
    "        r, r_op = tf.metrics.recall(labels=labels, predictions=predictions)\n",
    "        return 2 * p * r / (p + r), tf.group(p_op, r_op)        \n",
    "\n",
    "    def input_fn(self, mode, X, y=None, num_epochs=1):\n",
    "        if mode in [tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL]:\n",
    "            shuffle = True\n",
    "        else:\n",
    "            shuffle, num_epochs, y = (False, 1, None)\n",
    "        X = {self.features_key: X}\n",
    "        return tf.estimator.inputs.numpy_input_fn(X, y, self.batch_size,\n",
    "                                                  num_epochs, shuffle)\n",
    "\n",
    "    def model_fn(self, features, labels, mode, params):\n",
    "        # Network\n",
    "        logits = self.network_fn(features, params)\n",
    "        \n",
    "        # Predict\n",
    "        predicted_classes = tf.argmax(logits, 1)\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predicted_classes)        \n",
    "        \n",
    "        # Loss\n",
    "        class_M = self.label_encoder_.transform([\"M\"])\n",
    "        weights = tf.cast(tf.equal(labels, class_M), tf.float64)\n",
    "        weights = tf.multiply(weights, (6.63 - 1)) + 1\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits,\n",
    "                                                      weights=weights)\n",
    "        \n",
    "        # Eval\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, predictions=predicted_classes)\n",
    "        \n",
    "        # Train\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate=self.learning_rate)\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    def network_fn(self, features, params):\n",
    "        # Create embedding matrix\n",
    "        embeddings = tf.convert_to_tensor(self.embeddings)\n",
    "        unknown_words_embedding = tf.Variable(tf.random_uniform(\n",
    "            [1, self.embedding_dim], -1.0, 1.0, tf.float64), trainable=True)\n",
    "        embeddings = tf.concat([embeddings, unknown_words_embedding], axis=0)\n",
    "        \n",
    "        # Extract sequences embeddings\n",
    "        sequences = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "        embeddings = tf.nn.embedding_lookup(embeddings, tf.cast(sequences, tf.int64))\n",
    "        \n",
    "        # Convolutions and max poolings\n",
    "        feature_maps = []\n",
    "        iterator = zip([self.filters_by_ksize] * len(self.kernel_sizes), self.kernel_sizes)\n",
    "        for filters, kernel_size in iterator:\n",
    "            tmp = tf.layers.conv1d(embeddings, filters, kernel_size, padding=\"same\")\n",
    "            tmp = tf.layers.max_pooling1d(tmp, [self.sentence_length], strides=1, \n",
    "                                          padding=\"valid\")\n",
    "            feature_maps.append(tmp)\n",
    "        \n",
    "        # Concat all feature maps and add softmax\n",
    "        shape = [-1, self.filters_by_ksize * len(self.kernel_sizes)]\n",
    "        feature_maps = tf.reshape(tf.concat(feature_maps, axis=2), shape)\n",
    "        feature_maps = tf.nn.dropout(feature_maps, self.dropout_keep_prob)\n",
    "        logits = tf.layers.dense(feature_maps, self.n_classes_, activation=None)\n",
    "        return logits\n",
    "    \n",
    "    def fit_and_apply_transformers(self, X, y):\n",
    "        X = pad_sequences(X, self.sentence_length)\n",
    "        self.label_encoder_ = LabelEncoder()\n",
    "        y = self.label_encoder_.fit_transform(y)\n",
    "        self.n_classes_ = len(self.label_encoder_.classes_)\n",
    "        return X, y\n",
    "\n",
    "    def apply_transformers(self, X, y):\n",
    "        X = pad_sequences(X, self.sentence_length)\n",
    "        y = self.label_encoder_.transform(y)\n",
    "        return X, y\n",
    "\n",
    "    def fit(self, X, y, num_epochs=1, warm_start=True):\n",
    "        warm_start = self.check_warm_start(warm_start)\n",
    "        if not warm_start:\n",
    "            X, y = self.fit_and_apply_transformers(X, y)\n",
    "            self.classifier_ = self.create_dnn_classifier()\n",
    "        else:\n",
    "            X, y = self.apply_transformers(X, y)\n",
    "\n",
    "        self.classifier_.train(self.input_fn(\n",
    "            tf.estimator.ModeKeys.TRAIN, X, y, num_epochs))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pad_sequences(X, self.sentence_length)\n",
    "        classes = list(self.classifier_.predict(self.input_fn(\n",
    "            tf.estimator.ModeKeys.PREDICT, X)))\n",
    "        labels = self.label_encoder_.inverse_transform(classes)\n",
    "        return labels\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        X, y = self.apply_transformers(X, y)\n",
    "        results = self.classifier_.evaluate(self.input_fn(\n",
    "            tf.estimator.ModeKeys.EVAL, X, y))\n",
    "        return results[\"f1-score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "\n",
    "for lr in np.logspace(-6, 0, 7):\n",
    "    print(\"-\" * 80 + \"\\nLearning rate :\", lr)\n",
    "    model = DNNModel(\n",
    "        sentence_length=max(map(len, X_train)), \n",
    "        embeddings=embeddings,\n",
    "        kernel_sizes=(2,),\n",
    "        dropout_keep_prob=1.0,\n",
    "        filters_by_ksize=50,\n",
    "        learning_rate=lr,\n",
    "    )\n",
    "    for epoch in range(5):\n",
    "        model.fit(X_train, y_train, num_epochs=1, warm_start=True)\n",
    "        f1 = model.score(X_test, y_test)\n",
    "        print(\"EPOCH %d: test f1-score = %.3f\" % (epoch, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Learning rate : 1e-06\n",
      "EPOCH 0: test f1-score = nan\n",
      "EPOCH 1: test f1-score = nan\n",
      "EPOCH 2: test f1-score = nan\n",
      "EPOCH 3: test f1-score = nan\n",
      "EPOCH 4: test f1-score = nan\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate : 1e-05\n",
      "EPOCH 0: test f1-score = nan\n",
      "EPOCH 1: test f1-score = nan\n",
      "EPOCH 2: test f1-score = nan\n",
      "EPOCH 3: test f1-score = nan\n",
      "EPOCH 4: test f1-score = nan\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate : 0.0001\n",
      "EPOCH 0: test f1-score = 0.225\n",
      "EPOCH 1: test f1-score = 0.234\n",
      "EPOCH 2: test f1-score = 0.235\n",
      "EPOCH 3: test f1-score = 0.240\n",
      "EPOCH 4: test f1-score = 0.243\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate : 0.001\n",
      "EPOCH 0: test f1-score = 0.270\n",
      "EPOCH 1: test f1-score = 0.285\n",
      "EPOCH 2: test f1-score = 0.306\n",
      "EPOCH 3: test f1-score = 0.321\n",
      "EPOCH 4: test f1-score = 0.323\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate : 0.01\n",
      "EPOCH 0: test f1-score = 0.345\n",
      "EPOCH 1: test f1-score = 0.300\n",
      "EPOCH 2: test f1-score = 0.456\n",
      "EPOCH 3: test f1-score = 0.457\n",
      "EPOCH 4: test f1-score = 0.453\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate : 0.1\n",
      "EPOCH 0: test f1-score = 0.332\n",
      "EPOCH 1: test f1-score = 0.329\n",
      "EPOCH 2: test f1-score = 0.519\n",
      "EPOCH 3: test f1-score = 0.479\n",
      "EPOCH 4: test f1-score = 0.393\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate : 1.0\n",
      "EPOCH 0: test f1-score = 0.336\n",
      "EPOCH 1: test f1-score = 0.408\n",
      "EPOCH 2: test f1-score = 0.432\n",
      "EPOCH 3: test f1-score = 0.369\n",
      "EPOCH 4: test f1-score = 0.423\n"
     ]
    }
   ],
   "source": [
    "capt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "\n",
    "for lr in np.logspace(-3, -1, 6):\n",
    "    for ks in [(2,), (2, 3), (2, 3, 4), (2, 3, 4, 5)]:\n",
    "        for kp in [1.0, 0.9, 0.8, 0.7]:\n",
    "            print(\"-\" * 80 + \"\\nLearning rate:\", lr, \"- Kernel sizes:\", ks,\n",
    "                  \"- Dropout:\", kp)\n",
    "            model = DNNModel(\n",
    "                sentence_length=max(map(len, X_train)), \n",
    "                embeddings=embeddings,\n",
    "                filters_by_ksize=50,\n",
    "                learning_rate=lr,\n",
    "                kernel_sizes=ks,\n",
    "                dropout_keep_prob=kp,\n",
    "            )\n",
    "            for epoch in range(20):\n",
    "                model.fit(X_train, y_train, num_epochs=1, warm_start=True)\n",
    "                f1 = model.score(X_test, y_test)\n",
    "                print(\"EPOCH %d: test f1-score = %.3f\" % (epoch, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2,) - Dropout: 1.0\n",
      "EPOCH 0: test f1-score = 0.245\n",
      "EPOCH 1: test f1-score = 0.270\n",
      "EPOCH 2: test f1-score = 0.289\n",
      "EPOCH 3: test f1-score = 0.304\n",
      "EPOCH 4: test f1-score = 0.314\n",
      "EPOCH 5: test f1-score = 0.312\n",
      "EPOCH 6: test f1-score = 0.324\n",
      "EPOCH 7: test f1-score = 0.329\n",
      "EPOCH 8: test f1-score = 0.332\n",
      "EPOCH 9: test f1-score = 0.338\n",
      "EPOCH 10: test f1-score = 0.351\n",
      "EPOCH 11: test f1-score = 0.358\n",
      "EPOCH 12: test f1-score = 0.350\n",
      "EPOCH 13: test f1-score = 0.362\n",
      "EPOCH 14: test f1-score = 0.359\n",
      "EPOCH 15: test f1-score = 0.365\n",
      "EPOCH 16: test f1-score = 0.365\n",
      "EPOCH 17: test f1-score = 0.371\n",
      "EPOCH 18: test f1-score = 0.379\n",
      "EPOCH 19: test f1-score = 0.372\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2,) - Dropout: 0.9\n",
      "EPOCH 0: test f1-score = 0.243\n",
      "EPOCH 1: test f1-score = 0.263\n",
      "EPOCH 2: test f1-score = 0.278\n",
      "EPOCH 3: test f1-score = 0.288\n",
      "EPOCH 4: test f1-score = 0.288\n",
      "EPOCH 5: test f1-score = 0.306\n",
      "EPOCH 6: test f1-score = 0.310\n",
      "EPOCH 7: test f1-score = 0.316\n",
      "EPOCH 8: test f1-score = 0.316\n",
      "EPOCH 9: test f1-score = 0.322\n",
      "EPOCH 10: test f1-score = 0.336\n",
      "EPOCH 11: test f1-score = 0.343\n",
      "EPOCH 12: test f1-score = 0.338\n",
      "EPOCH 13: test f1-score = 0.337\n",
      "EPOCH 14: test f1-score = 0.346\n",
      "EPOCH 15: test f1-score = 0.350\n",
      "EPOCH 16: test f1-score = 0.349\n",
      "EPOCH 17: test f1-score = 0.357\n",
      "EPOCH 18: test f1-score = 0.364\n",
      "EPOCH 19: test f1-score = 0.352\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2,) - Dropout: 0.8\n",
      "EPOCH 0: test f1-score = 0.240\n",
      "EPOCH 1: test f1-score = 0.250\n",
      "EPOCH 2: test f1-score = 0.267\n",
      "EPOCH 3: test f1-score = 0.273\n",
      "EPOCH 4: test f1-score = 0.283\n",
      "EPOCH 5: test f1-score = 0.291\n",
      "EPOCH 6: test f1-score = 0.303\n",
      "EPOCH 7: test f1-score = 0.312\n",
      "EPOCH 8: test f1-score = 0.317\n",
      "EPOCH 9: test f1-score = 0.311\n",
      "EPOCH 10: test f1-score = 0.313\n",
      "EPOCH 11: test f1-score = 0.337\n",
      "EPOCH 12: test f1-score = 0.332\n",
      "EPOCH 13: test f1-score = 0.344\n",
      "EPOCH 14: test f1-score = 0.330\n",
      "EPOCH 15: test f1-score = 0.346\n",
      "EPOCH 16: test f1-score = 0.345\n",
      "EPOCH 17: test f1-score = 0.347\n",
      "EPOCH 18: test f1-score = 0.347\n",
      "EPOCH 19: test f1-score = 0.347\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2,) - Dropout: 0.7\n",
      "EPOCH 0: test f1-score = 0.239\n",
      "EPOCH 1: test f1-score = 0.257\n",
      "EPOCH 2: test f1-score = 0.271\n",
      "EPOCH 3: test f1-score = 0.282\n",
      "EPOCH 4: test f1-score = 0.296\n",
      "EPOCH 5: test f1-score = 0.290\n",
      "EPOCH 6: test f1-score = 0.308\n",
      "EPOCH 7: test f1-score = 0.315\n",
      "EPOCH 8: test f1-score = 0.321\n",
      "EPOCH 9: test f1-score = 0.328\n",
      "EPOCH 10: test f1-score = 0.329\n",
      "EPOCH 11: test f1-score = 0.332\n",
      "EPOCH 12: test f1-score = 0.335\n",
      "EPOCH 13: test f1-score = 0.354\n",
      "EPOCH 14: test f1-score = 0.345\n",
      "EPOCH 15: test f1-score = 0.346\n",
      "EPOCH 16: test f1-score = 0.354\n",
      "EPOCH 17: test f1-score = 0.356\n",
      "EPOCH 18: test f1-score = 0.366\n",
      "EPOCH 19: test f1-score = 0.367\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2, 3) - Dropout: 1.0\n",
      "EPOCH 0: test f1-score = 0.267\n",
      "EPOCH 1: test f1-score = 0.285\n",
      "EPOCH 2: test f1-score = 0.310\n",
      "EPOCH 3: test f1-score = 0.334\n",
      "EPOCH 4: test f1-score = 0.327\n",
      "EPOCH 5: test f1-score = 0.329\n",
      "EPOCH 6: test f1-score = 0.346\n",
      "EPOCH 7: test f1-score = 0.356\n",
      "EPOCH 8: test f1-score = 0.363\n",
      "EPOCH 9: test f1-score = 0.361\n",
      "EPOCH 10: test f1-score = 0.358\n",
      "EPOCH 11: test f1-score = 0.366\n",
      "EPOCH 12: test f1-score = 0.377\n",
      "EPOCH 13: test f1-score = 0.379\n",
      "EPOCH 14: test f1-score = 0.384\n",
      "EPOCH 15: test f1-score = 0.380\n",
      "EPOCH 16: test f1-score = 0.389\n",
      "EPOCH 17: test f1-score = 0.386\n",
      "EPOCH 18: test f1-score = 0.398\n",
      "EPOCH 19: test f1-score = 0.380\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2, 3) - Dropout: 0.9\n",
      "EPOCH 0: test f1-score = 0.255\n",
      "EPOCH 1: test f1-score = 0.261\n",
      "EPOCH 2: test f1-score = 0.283\n",
      "EPOCH 3: test f1-score = 0.292\n",
      "EPOCH 4: test f1-score = 0.298\n",
      "EPOCH 5: test f1-score = 0.314\n",
      "EPOCH 6: test f1-score = 0.325\n",
      "EPOCH 7: test f1-score = 0.329\n",
      "EPOCH 8: test f1-score = 0.343\n",
      "EPOCH 9: test f1-score = 0.342\n",
      "EPOCH 10: test f1-score = 0.340\n",
      "EPOCH 11: test f1-score = 0.350\n",
      "EPOCH 12: test f1-score = 0.360\n",
      "EPOCH 13: test f1-score = 0.361\n",
      "EPOCH 14: test f1-score = 0.375\n",
      "EPOCH 15: test f1-score = 0.358\n",
      "EPOCH 16: test f1-score = 0.369\n",
      "EPOCH 17: test f1-score = 0.371\n",
      "EPOCH 18: test f1-score = 0.381\n",
      "EPOCH 19: test f1-score = 0.384\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2, 3) - Dropout: 0.8\n",
      "EPOCH 0: test f1-score = 0.234\n",
      "EPOCH 1: test f1-score = 0.248\n",
      "EPOCH 2: test f1-score = 0.269\n",
      "EPOCH 3: test f1-score = 0.280\n",
      "EPOCH 4: test f1-score = 0.296\n",
      "EPOCH 5: test f1-score = 0.296\n",
      "EPOCH 6: test f1-score = 0.305\n",
      "EPOCH 7: test f1-score = 0.322\n",
      "EPOCH 8: test f1-score = 0.320\n",
      "EPOCH 9: test f1-score = 0.346\n",
      "EPOCH 10: test f1-score = 0.345\n",
      "EPOCH 11: test f1-score = 0.344\n",
      "EPOCH 12: test f1-score = 0.347\n",
      "EPOCH 13: test f1-score = 0.358\n",
      "EPOCH 14: test f1-score = 0.349\n",
      "EPOCH 15: test f1-score = 0.358\n",
      "EPOCH 16: test f1-score = 0.364\n",
      "EPOCH 17: test f1-score = 0.376\n",
      "EPOCH 18: test f1-score = 0.379\n",
      "EPOCH 19: test f1-score = 0.377\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2, 3) - Dropout: 0.7\n",
      "EPOCH 0: test f1-score = 0.242\n",
      "EPOCH 1: test f1-score = 0.260\n",
      "EPOCH 2: test f1-score = 0.275\n",
      "EPOCH 3: test f1-score = 0.290\n",
      "EPOCH 4: test f1-score = 0.306\n",
      "EPOCH 5: test f1-score = 0.309\n",
      "EPOCH 6: test f1-score = 0.310\n",
      "EPOCH 7: test f1-score = 0.320\n",
      "EPOCH 8: test f1-score = 0.330\n",
      "EPOCH 9: test f1-score = 0.335\n",
      "EPOCH 10: test f1-score = 0.343\n",
      "EPOCH 11: test f1-score = 0.348\n",
      "EPOCH 12: test f1-score = 0.363\n",
      "EPOCH 13: test f1-score = 0.357\n",
      "EPOCH 14: test f1-score = 0.367\n",
      "EPOCH 15: test f1-score = 0.366\n",
      "EPOCH 16: test f1-score = 0.363\n",
      "EPOCH 17: test f1-score = 0.362\n",
      "EPOCH 18: test f1-score = 0.371\n",
      "EPOCH 19: test f1-score = 0.374\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2, 3, 4) - Dropout: 1.0\n",
      "EPOCH 0: test f1-score = 0.280\n",
      "EPOCH 1: test f1-score = 0.307\n",
      "EPOCH 2: test f1-score = 0.346\n",
      "EPOCH 3: test f1-score = 0.335\n",
      "EPOCH 4: test f1-score = 0.363\n",
      "EPOCH 5: test f1-score = 0.362\n",
      "EPOCH 6: test f1-score = 0.372\n",
      "EPOCH 7: test f1-score = 0.382\n",
      "EPOCH 8: test f1-score = 0.385\n",
      "EPOCH 9: test f1-score = 0.396\n",
      "EPOCH 10: test f1-score = 0.391\n",
      "EPOCH 11: test f1-score = 0.373\n",
      "EPOCH 12: test f1-score = 0.395\n",
      "EPOCH 13: test f1-score = 0.395\n",
      "EPOCH 14: test f1-score = 0.405\n",
      "EPOCH 15: test f1-score = 0.417\n",
      "EPOCH 16: test f1-score = 0.406\n",
      "EPOCH 17: test f1-score = 0.394\n",
      "EPOCH 18: test f1-score = 0.422\n",
      "EPOCH 19: test f1-score = 0.417\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2, 3, 4) - Dropout: 0.9\n",
      "EPOCH 0: test f1-score = 0.265\n",
      "EPOCH 1: test f1-score = 0.288\n",
      "EPOCH 2: test f1-score = 0.308\n",
      "EPOCH 3: test f1-score = 0.312\n",
      "EPOCH 4: test f1-score = 0.318\n",
      "EPOCH 5: test f1-score = 0.346\n",
      "EPOCH 6: test f1-score = 0.333\n",
      "EPOCH 7: test f1-score = 0.342\n",
      "EPOCH 8: test f1-score = 0.357\n",
      "EPOCH 9: test f1-score = 0.369\n",
      "EPOCH 10: test f1-score = 0.358\n",
      "EPOCH 11: test f1-score = 0.364\n",
      "EPOCH 12: test f1-score = 0.381\n",
      "EPOCH 13: test f1-score = 0.378\n",
      "EPOCH 14: test f1-score = 0.374\n",
      "EPOCH 15: test f1-score = 0.386\n",
      "EPOCH 16: test f1-score = 0.388\n",
      "EPOCH 17: test f1-score = 0.383\n",
      "EPOCH 18: test f1-score = 0.391\n",
      "EPOCH 19: test f1-score = 0.403\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2, 3, 4) - Dropout: 0.8\n",
      "EPOCH 0: test f1-score = 0.243\n",
      "EPOCH 1: test f1-score = 0.280\n",
      "EPOCH 2: test f1-score = 0.298\n",
      "EPOCH 3: test f1-score = 0.312\n",
      "EPOCH 4: test f1-score = 0.314\n",
      "EPOCH 5: test f1-score = 0.323\n",
      "EPOCH 6: test f1-score = 0.327\n",
      "EPOCH 7: test f1-score = 0.345\n",
      "EPOCH 8: test f1-score = 0.351\n",
      "EPOCH 9: test f1-score = 0.358\n",
      "EPOCH 10: test f1-score = 0.358\n",
      "EPOCH 11: test f1-score = 0.358\n",
      "EPOCH 12: test f1-score = 0.372\n",
      "EPOCH 13: test f1-score = 0.379\n",
      "EPOCH 14: test f1-score = 0.376\n",
      "EPOCH 15: test f1-score = 0.373\n",
      "EPOCH 16: test f1-score = 0.384\n",
      "EPOCH 17: test f1-score = 0.381\n",
      "EPOCH 18: test f1-score = 0.393\n",
      "EPOCH 19: test f1-score = 0.388\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2, 3, 4) - Dropout: 0.7\n",
      "EPOCH 0: test f1-score = 0.247\n",
      "EPOCH 1: test f1-score = 0.259\n",
      "EPOCH 2: test f1-score = 0.266\n",
      "EPOCH 3: test f1-score = 0.280\n",
      "EPOCH 4: test f1-score = 0.298\n",
      "EPOCH 5: test f1-score = 0.302\n",
      "EPOCH 6: test f1-score = 0.305\n",
      "EPOCH 7: test f1-score = 0.319\n",
      "EPOCH 8: test f1-score = 0.322\n",
      "EPOCH 9: test f1-score = 0.329\n",
      "EPOCH 10: test f1-score = 0.340\n",
      "EPOCH 11: test f1-score = 0.355\n",
      "EPOCH 12: test f1-score = 0.365\n",
      "EPOCH 13: test f1-score = 0.358\n",
      "EPOCH 14: test f1-score = 0.356\n",
      "EPOCH 15: test f1-score = 0.367\n",
      "EPOCH 16: test f1-score = 0.372\n",
      "EPOCH 17: test f1-score = 0.367\n",
      "EPOCH 18: test f1-score = 0.367\n",
      "EPOCH 19: test f1-score = 0.379\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2, 3, 4, 5) - Dropout: 1.0\n",
      "EPOCH 0: test f1-score = 0.284\n",
      "EPOCH 1: test f1-score = 0.322\n",
      "EPOCH 2: test f1-score = 0.345\n",
      "EPOCH 3: test f1-score = 0.318\n",
      "EPOCH 4: test f1-score = 0.322\n",
      "EPOCH 5: test f1-score = 0.349\n",
      "EPOCH 6: test f1-score = 0.338\n",
      "EPOCH 7: test f1-score = 0.380\n",
      "EPOCH 8: test f1-score = 0.374\n",
      "EPOCH 9: test f1-score = 0.365\n",
      "EPOCH 10: test f1-score = 0.350\n",
      "EPOCH 11: test f1-score = 0.411\n",
      "EPOCH 12: test f1-score = 0.397\n",
      "EPOCH 13: test f1-score = 0.383\n",
      "EPOCH 14: test f1-score = 0.392\n",
      "EPOCH 15: test f1-score = 0.392\n",
      "EPOCH 16: test f1-score = 0.401\n",
      "EPOCH 17: test f1-score = 0.393\n",
      "EPOCH 18: test f1-score = 0.414\n",
      "EPOCH 19: test f1-score = 0.424\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.001 - Kernel sizes: (2, 3, 4, 5) - Dropout: 0.9\n",
      "EPOCH 0: test f1-score = 0.269\n",
      "EPOCH 1: test f1-score = 0.296\n",
      "EPOCH 2: test f1-score = 0.309\n",
      "EPOCH 3: test f1-score = 0.326\n",
      "EPOCH 4: test f1-score = 0.340\n",
      "EPOCH 5: test f1-score = 0.341\n",
      "EPOCH 6: test f1-score = 0.368\n",
      "EPOCH 7: test f1-score = 0.368\n",
      "EPOCH 8: test f1-score = 0.373\n",
      "EPOCH 9: test f1-score = 0.373\n",
      "EPOCH 10: test f1-score = 0.389\n",
      "EPOCH 11: test f1-score = 0.387\n"
     ]
    }
   ],
   "source": [
    "capt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "\n",
    "for lr in np.logspace(-3, -1, 6)[1:]:\n",
    "    print(\"-\" * 80 + \"\\nLearning rate:\", lr)\n",
    "    model = DNNModel(\n",
    "        sentence_length=max(map(len, X_train)), \n",
    "        embeddings=embeddings,\n",
    "        dropout_keep_prob=1.0,\n",
    "        filters_by_ksize=50,\n",
    "        kernel_sizes=(2, 3, 4, 5),\n",
    "        learning_rate=lr,\n",
    "    )\n",
    "    for epoch in range(5):\n",
    "        model.fit(X_train, y_train, num_epochs=1, warm_start=True)\n",
    "        f1 = model.score(X_test, y_test)\n",
    "        print(\"EPOCH %d: test f1-score = %.3f\" % (epoch, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.0025118864315095794\n",
      "EPOCH 0: test f1-score = 0.340\n",
      "EPOCH 1: test f1-score = 0.371\n",
      "EPOCH 2: test f1-score = 0.357\n",
      "EPOCH 3: test f1-score = 0.406\n",
      "EPOCH 4: test f1-score = 0.404\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.00630957344480193\n",
      "EPOCH 0: test f1-score = 0.385\n",
      "EPOCH 1: test f1-score = 0.332\n",
      "EPOCH 2: test f1-score = 0.362\n",
      "EPOCH 3: test f1-score = 0.390\n",
      "EPOCH 4: test f1-score = 0.450\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.01584893192461114\n",
      "EPOCH 0: test f1-score = 0.339\n",
      "EPOCH 1: test f1-score = 0.397\n",
      "EPOCH 2: test f1-score = 0.491\n",
      "EPOCH 3: test f1-score = 0.482\n",
      "EPOCH 4: test f1-score = 0.464\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.039810717055349734\n",
      "EPOCH 0: test f1-score = 0.451\n",
      "EPOCH 1: test f1-score = 0.504\n",
      "EPOCH 2: test f1-score = 0.528\n",
      "EPOCH 3: test f1-score = 0.528\n",
      "EPOCH 4: test f1-score = 0.458\n",
      "--------------------------------------------------------------------------------\n",
      "Learning rate: 0.1\n",
      "EPOCH 0: test f1-score = 0.451\n",
      "EPOCH 1: test f1-score = 0.516\n",
      "EPOCH 2: test f1-score = 0.540\n",
      "EPOCH 3: test f1-score = 0.509\n",
      "EPOCH 4: test f1-score = 0.524\n"
     ]
    }
   ],
   "source": [
    "capt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0: test f1-score = 0.342\n",
      "EPOCH 1: test f1-score = 0.423\n",
      "EPOCH 2: test f1-score = 0.458\n",
      "EPOCH 3: test f1-score = 0.514\n",
      "EPOCH 4: test f1-score = 0.426\n",
      "EPOCH 5: test f1-score = 0.523\n"
     ]
    }
   ],
   "source": [
    "model = DNNModel(\n",
    "    sentence_length=max(map(len, X_train)), \n",
    "    embeddings=embeddings,\n",
    "    filters_by_ksize=50,\n",
    "    kernel_sizes=(2, 3, 4, 5),\n",
    "    learning_rate=0.1,\n",
    "    dropout_keep_prob=0.5,\n",
    ")\n",
    "for epoch in range(10):\n",
    "    model.fit(X_train, y_train, num_epochs=1, warm_start=True)\n",
    "    f1 = model.score(X_test, y_test)\n",
    "    print(\"EPOCH %d: test f1-score = %.3f\" % (epoch, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
